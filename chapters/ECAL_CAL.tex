
\section{Introduction}

ECAL is designed to measure the energy deposited by electrons and photons. These particles deposit their energy in ECAL by showering in the ECAL crystals.

EM showers spread over multiple crystals. (small Molière radius 2.19 cm while crystal transverse size is close 2.6 cm). clusters are extended in phi direction to form "superclusters" to recover energy radiated via bremsstrahlung or conversion. (connect with PF section)

To get the correct energy for a photon we generally include different types of corrections like intercalibration which done before data taking to equalize signal response for the same eta. Also, Laser corrections, that is done every 40 mins for signal transparency loss (or photocathode aging). lastly in situ. The last type is the focus of this work. (here include equation related to calibration). PF cluster correction is obtained from a regression method.

The reconstructed PF cluster energy is expected to be smaller than the energy of the incoming particle. This loss of energy could be due to tracker material, gaps, dead channels etc. Therefore, a calibration of the calorimeter cluster energy is needed.

This chapter presents the used ML method BDT and datasets in performing the PF ECAL cluster calibration (online/offline). 


\section{XGBoost} %source1  source2 

The ML algorithm used to calibrate the ECAL pf cluster is called XGBoost algorithm. XGBoost stands for Extreme gradient boosting which is a type of gradient boosting. Gradient boosting uses the gradient decent (clarify better – how is calculated) to create new the learners where the loss function, which define the distance between the truth and prediction, is differentiable.  (find the related figure)

this algorithm works by combining the boosting technique and many decision trees to get the final prediction to achieve higher accuracy. During training process: The algorithm starts with an initial prediction and compute the residuals, loss. Then it creates other decision trees using a similarity score for the residuals (clarify better) which are then used to generate the output values for each leaf.  This process is repeated either until the residuals (error) stop reducing or for a specific number of times. In general, each subsequent tree learns from the previous ones.

XGBoost uses assign higher importance to the misclassified sample during the reconstruction of the next tree. Meaning the next tree can focus on correcting those mistakes and by doing that the algorithm improves its accuracy. To prevent overfitting, the algorithm is uses of a regularization term.


\section{Datasets description}

The first part of this thesis work focuses on the calibration of ECAL PF clusters for Run3. The samples used for this calibration are double photon with zero material Monte Carlo (MC) samples. Double photon to increase the statistics, and zero material meaning there is no material in front of the calorimeter to eliminate dealing with bremsstrahlung and photon conversions.

The datasets are centrally produced, and reconstructed in CMSSW 13.3.0 (133X) under 2024 conditions. These samples can be found through Data Aggregation System (DAS) web page. There are two types of datasets used here, one with Pile up (PU) 80, meaning 80 collisions occurring simultaneously within one p-p bunch crossing, %source,  
and another with no pile (NoPU). Both correspond to a center of mass energy 13.6 TeV with pt range up to 1500 GeV/c.

Before splitting the data samples into two groups,80\% training and 20\% testing, the training samples need to be divided into smaller groups. This is done to get better models when training the ML algorithm. The NoPU training samples will be divided first into two categories Full readout and Zero suppression (ZS) (explain difference). %source  
Then each category will be split further more depending on ECAL region and pt range. In the end we end up with 6 groups for Full readout and 2 groups for ZS readout. (add table summarize the samples description)  


\section{PF ECAL cluster regression}
The ML method implemented for PF ECAL cluster calibration is a Boosted Decision Tree (BDT) (XGBoost) that is based on a semi-parametric regression (it combines parametric and nonparametric models %source).

The PF cluster regression here is (Regression in machine learning refers to a supervised learning technique where the goal is to predict a continuous numerical value based on one or more independent features. source) done intro two steps: training (using only NOPU dataset, 8 datasets). Then validation of the training is done on NOPU and PU (80) samples.

To estimate the correction to the PF ECAL Cluster we consider the case where a one photon has deposited all its energy in one PF cluster in the ECAL.  (as mentioned in the data description zero material means that the CMS material in front of the calorimeter would not results in bremsstrahlung and photon conversions which will require superclusters to reconstruct the all the energy). This will allow us to calculate for the correction factor to be: Energy of “gen photon” / E “raw pf cluster” that will be used later in testing the results of the ML training.

The training input variables (features) include independent variables used in the training:   
ClusrawE (raw energy of the cluster, uncorrected), 
ieta,iphi (polar coordinates for EB), 
ix, iy (cartesian coordinates for EE), 
ieta mod20, iphi mod20 (these are polar coordinate of the crystal in which the main cluster detected modulo 20 EB), 
(clusPS1+clusPS2)/clusrawE (clusPSi: cluster in pre shower layer i, only EE),   
number of hits in the cluster (which takes values 1, 2 and 3 - it takes 3 if n hits >= 3) (side note here: Approximately 94  of the incident energy of a single electron or photon is contained in 3x3 crystals, and 97  in 5x5 crystals source). The target used here is log (Egen/Eraw).(Mostly lognormal distribution distribution in energies? source). These variables are the same as the one used previously Run 2 calibration.

Then validation of ML is done through few steps:  
first, from the training model we get the value of the correction factor. (Egen/Eraw)) 
Then, calculate the corrected (calibrated) cluster energy = E “raw pf cluster” * correction factor.  
Plot: the response which will be equal to E “corrected cluster” / E “gen photon”. 
Fit the plot with: double CB function. (for pt< 6 GeV we use Gaus function for fitting) 
From the fitted curve we find: mean, effective sigma. also We can also get the mean, effective sigma for raw PF cluster energy “with no correction” to compare by doing the same.





\section{results}

The presented plots show a comparison between the calibration results of the new (presented) corrected ECAL cluster in 133X (blue line), to the current (previous) correction in 126X (green) and raw PF ECAL cluster (red). (what has changed between the new and previous correction? Just the sample conditions? Which affected the model used in the training?)  

generally, we see that the new correction very close to the current used calibration. Usually, the since the PF clustering is performed separately in each region (this is mentioned in PF section) of the ECAL: ECAL Barrel (EB), ECAL Endcaps (EE). calibrations is done in a similar way.

Overview of the results: we checked the 2024 double photon calibration samples for PF ECAL clusters. In general, the existing calibration derived from 2022 samples seems to continue to be working well. (note: add comment about future calibration for ECAL PF cluster)


\subsection{offline PF ECAL cluster}

%\subsubsection{ECAL Barrel}
first starting with the NOPU sample then the PU case. in ECAL Barrel region. 

plots show response (resolution) vs Pt gen in GeV and in their corresponding eta range.
\include{./plots_tex/PU_EB_FULL_plots}
\include{./plots_tex/PU_EB_ZS_plots}
\include{./plots_tex/NOPU_EB_FULL_plots}
\include{./plots_tex/NOPU_EB_ZS_plots}

%\subsubsection{ECAL Endcap}

in EE region:
\include{./plots_tex/NOPU_EE_FULL_plots}
\include{./plots_tex/NOPU_EE_ZS_plots}
\include{./plots_tex/PU_EE_FULL_plots}
\include{./plots_tex/PU_EE_ZS_plots}

\subsection{HLT vs offline PF ECAL cluster}

(connect to PF chapter where where we mentioned offline PF)
(also mention the procution of a new ntuple that containes HLT information) 

first for NoPU samples
\include{./plots_tex/NoPU_HLT_offline_plots}
Second for PUU samples
\include{./plots_tex/PU_HLT_offline_plots}
