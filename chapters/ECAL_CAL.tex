
\section{Introduction}

ECAL is designed to measure the energy deposited by electrons and photons. These particles deposit their energy in ECAL by showering in the ECAL crystals.

EM showers spread over multiple crystals. (small Molière radius 2.19 cm while crystal transverse size is close 2.6 cm). clusters are extended in phi direction to form "superclusters" to recover energy radiated via bremsstrahlung or conversion. (connect with PF section)

To get the correct energy for a photon we generally include different types of corrections like intercalibration which done before data taking to equalize signal response for the same eta. Also, Laser corrections, that is done every 40 mins for signal transparency loss (or photocathode aging). lastly in situ. The last type is the focus of this work. (here include equation related to calibration). PF cluster correction is obtained from a regression method.

The reconstructed PF cluster energy is expected to be smaller than the energy of the incoming particle. This loss of energy could be due to tracker material, gaps, dead channels etc. Therefore, a calibration of the calorimeter cluster energy is needed.

This chapter presents the used ML method BDT and datasets in performing the PF ECAL cluster calibration (online/offline). 


\section{XGBoost} %source1  source2 

The ML algorithm used to calibrate the ECAL pf cluster is called XGBoost algorithm. XGBoost stands for Extreme gradient boosting which is a type of gradient boosting. Gradient boosting uses the gradient decent (clarify better – how is calculated) to create new the learners where the loss function, which define the distance between the truth and prediction, is differentiable.  (find the related figure)

this algorithm works by combining the boosting technique and many decision trees to get the final prediction to achieve higher accuracy. During training process: The algorithm starts with an initial prediction and compute the residuals, loss. Then it creates other decision trees using a similarity score for the residuals (clarify better) which are then used to generate the output values for each leaf.  This process is repeated either until the residuals (error) stop reducing or for a specific number of times. In general, each subsequent tree learns from the previous ones.

XGBoost uses assign higher importance to the misclassified sample during the reconstruction of the next tree. Meaning the next tree can focus on correcting those mistakes and by doing that the algorithm improves its accuracy. To prevent overfitting, the algorithm is uses of a regularization term.


\section{Datasets description}

The first part of this thesis work focuses on the calibration of ECAL PF clusters for Run3. The samples used for this calibration are double photon with zero material Monte Carlo (MC) samples. Double photon to increase the statistics, and zero material meaning there is no material in front of the calorimeter to eliminate dealing with bremsstrahlung and photon conversions.

The datasets are centrally produced, and reconstructed in CMSSW 13.3.0 (133X) under 2024 conditions. These samples can be found through Data Aggregation System (DAS) web page. There are two types of datasets used here, one with Pile up (PU) 80, meaning 80 collisions occurring simultaneously within one p-p bunch crossing, %source,  
and another with no pile (NoPU). Both correspond to a center of mass energy 13.6 TeV with pt range up to 1500 GeV/c.

Before splitting the data samples into two groups,80\% training and 20\% testing, the training samples need to be divided into smaller groups. This is done to get better models when training the ML algorithm. The NoPU training samples will be divided first into two categories Full readout and Zero suppression (ZS) (explain difference). %source  
Then each category will be split further more depending on ECAL region and pt range. In the end we end up with 6 groups for Full readout and 2 groups for ZS readout. (add table summarize the samples description)  


\section{PF ECAL cluster regression}
The ML used for PF ECAL cluster regression is called XGBoost algorithm. (which has been covered in the previous section). The PF cluster regression here is done through two steps: first phase: training the ML algorithm using training data (NoPU).Second phase, testing the ML model using testing data (NoPU, PU).

First, we starting with the training details. To estimate the calibration of the PF ECAL Cluster we consider the case where a one photon has deposited all its energy in one PF cluster in the ECAL, since we have zero material as mentioned before (Approximately 94\% of the incident energy of a single electron or photon is contained in 3x3 crystals, and 97\% in 5x5 crystals source).  
This allows us to calculate the correction factor = Energy of “generated photon” / E “raw PF cluster”.

For the training variables we are using the same variables for Run 2 and Run 3 (2023) calibration. The training input variables are summarized in the related table, this includes:  
ClusrawE (raw energy of the cluster, uncorrected), 
ieta,iphi (polar coordinates for clusters in EB), 
ix, iy (cartesian coordinates for clusters in EE), 
ieta mod20, iphi mod20 (these are polar coordinate of the crystal in which the main cluster detected modulo 20 for clusters in EB), 
(clusPS1+clusPS2)/clusrawE (clusPSi: cluster in pre shower layer i, only EE), 
 number of hits in the cluster (which takes values 1, 2 and 3 - it takes 3 if n hits >= 3), 
and the target used in the training is log (Egen/Eraw)  
%(Mostly lognormal distribution in energies? source).

After training is done, we get 8 regression models form each group in the training data. To validated the results of ML training we apply the following steps: 
first, we apply the trained model on the test data to get the value of the correction factor, 
then calculate:  the corrected PF cluster energy = E “raw pf cluster” * correction factor, 
after that we plot: the response: E “corrected PF cluster” / E “gen photon”, 
next we fit the plot with: double CB function for each E “gen photon” bin (notes (for pt< 6 GeV we use Gaus function for fitting since it will be difficult to do the with double CB- in other words low pt (zero suppressed)) 
finally, From the fitted curve we find: mean, effective sigma.  

We can also plot the response: E “raw PF cluster” / E “gen photon”, to compare mean and eff sigma to the corrected PF cluster. (insert an example plots of the fitting)   
\section{results}
We checked the 2024 double photon calibration samples for PF ECAL clusters. Generally, the new correction (133X) is very close to the current used calibration (126X). This shows that the existing calibration derived from 2022 samples seems to continue to working well. (Add comments about HLT vs offline calibration)

The next presented plots show a comparison between the energy response of: 
 raw PF cluster (red line), corrected PF ECAL cluster using previous correction in 126X (green line),  
corrected PF ECAL cluster by the calibration in 133X, presented in this chapter (blue line).

\subsection{offline PF ECAL cluster}

%\subsubsection{ECAL Barrel}
first starting with the NOPU sample then the PU case. in ECAL Barrel region. 

plots show response (resolution) vs Pt gen in GeV and in their corresponding eta range.
\include{./plots_tex/PU_EB_FULL_plots}
\include{./plots_tex/PU_EB_ZS_plots}
\include{./plots_tex/NOPU_EB_FULL_plots}
\include{./plots_tex/NOPU_EB_ZS_plots}

%\subsubsection{ECAL Endcap}

in EE region:
\include{./plots_tex/NOPU_EE_FULL_plots}
\include{./plots_tex/NOPU_EE_ZS_plots}
\include{./plots_tex/PU_EE_FULL_plots}
\include{./plots_tex/PU_EE_ZS_plots}

\subsection{HLT vs offline PF ECAL cluster}

(connect to PF chapter where where we mentioned offline PF)
(also mention the procution of a new ntuple that containes HLT information) 

first for NoPU samples
\include{./plots_tex/NoPU_HLT_offline_plots}
Second for PUU samples
\include{./plots_tex/PU_HLT_offline_plots}
