\section{Introduction}
The last set of PF candidates that are reconstructed are hadrons. The calorimetric measurements, energy clusters, are the only way to identify neutral hadrons while these measurements complement the track measurements for charged hadrons. When hadrons enter calorimeters, some hadrons start showering in the ECAL and extend to the HCAL (EH-hadrons), while others do not have nuclear interactions until the HCAL (H-hadrons). Hadronic showers have electromagnetic (EM) and hadronic (HAD) components. A key feature of hadronic showers is the fluctuations in the invisible energy lost in binding energy or target recoil, particle type, and particle multiplicity generated by the same incident particle. %source
For the previous reasons, the energy response for hadrons is generally non-linear.

This chapter introduces the details of testing an ML technique, Dynamic Reduction Network (DRN), in performing a PF hadron cluster calibration.

%---------------------------------------
%1source https://www.desy.de/~schleper/lehre/Det_Dat/SS_2018/06_lecture_calorimetry_HAD.pdf

\section{Graph Neural Network} %source
Graph neural network (GNN) is a type of NN used to process data that can be represented as graphs. Compared to other kinds of NN, GNN can be applied to sparse data, such as rechits. %(introduce rechits)
As shown in (fig), a graph consists of nodes and edges. Nodes represent the objects, and edges reflect the relationship between the nodes. In our case, rechits are the nodes, and the edges represent their connection in a cluster. Graph Convolutional Networks (GCNs)(source) relies on message-passing methods to exchange information and messages between the neighbors (rechits). GCNs work through two steps. First, each node creates a feature vector representing the message it wants to share with others. In the second step, messages are sent to the neighbors so that each node learns about its neighbors and itself. In (fig), there is a visualization of message passing.

\section{Datasets Description}
The second part of this thesis focuses on correcting charged hadron PF clusters for Run~3. Single pion gun Monte Carlo (MC) samples are used for this calibration. The datasets are centrally produced and reconstructed under CMSSW 12\_6\_4 (126X) under the 2023 condition. These samples are also available through the DAS web page and cover energy ranges of 2--200 GeV and 200--500 GeV. For training the ML model, the data are divided into EH-hadrons and H-hadrons. %(add figure shows EH.H location in CMS)

\section{PF Cluster Regression using DRN}
Dynamic Reduction Network (DRN) (source) is based on the Graph Neural Network (GNN) used in this thesis to reconstruct hadron (pion) showers in the calorimeters.
A schematic drawing of the DRN is shown in (fig), and a summary of the information flow from the inputs to the targets is as follows:

First, the input features, the coordinates ({\tt x}, {\tt y}, and {\tt z)} and energy ({\tt E}) of rechits in a point cloud image of the detectors are mapped onto a 64-dimensional latent space using a fully connected neural network (FCNN).
The FCNN is a multi-layer perceptron (MLP) encoder with a depth of three layers connected by activation functions (exponential linear unit, ELU).

Second, high-level features are learned using the GNN techniques by repeating the following steps twice.
Starting with a graph generation (KNN) step, each point in the point cloud in the 64-dimensional latent space is connected to its 16 nearest neighboring nodes, including itself, to form graphs.
We have 3D point clouds, scattered collections of points (clusters) (source.)
Each node (input) is connected to its {\tt K} nearest neighbors in the feature space. The direct graph has vertices and edges. %(k=100)
Then, in the graph convolution step, the resulting graphs are processed using the operation “EdgeConv,” where two-layer (here 2 or 3) fully connected networks are used to create messages sent along the edges of the graph.
These messages are aggregated at each node in the graph to form the new node feature. %(define edge features)
Next, in the graph clustering and pooling, graph clustering uses the Graclus Clustering algorithm and pooling step.
In this step, the updated features are weighted by distance, and the clusters are combined using a max-pooling strategy to form a single point.

The final set of nodes is reduced using global max-pooling and passed through an FCNN to obtain the final target, which in our case is the pion energy or some variable related to the correction factor on the raw PF cluster energy.

\section{Results}
The results of response and resolution in both barrel region and endcap region are shown in Figs.~\ref{fig:H_ratioflip}--\ref{fig:EH_trueE}.
The results are shown for the calibrations based on the DRN and traditional method based on $\chi^2$ fit to the response distribution.
Results for H hadrons are shown in Figs.~\ref{fig:H_ratioflip}-\ref{fig:H_trueE} and results for EH hadrons are shown in Figs.~\ref{fig:EH_ratioflip}--\ref{fig:EH_trueE}.
Results are shown for four different targets used for the training.
Overall regardless of the training targets, the DRN model provides a good response distribution, although the response becomes a little unstable for the endcap region outside the tracker overage (\ie, $|\eta|>2.5$).
In terms of the resolution, the DRN model generally provides either similar performance or slight improvements over the traditional $\chi^2$ method for the H hadron case.
More significant improvements are observed for EH hadrons and the improvement in resolution are up to a factor 2.
These results are still shown only for isolated single pions in simulation with pileup interactions, and we still need to see how it will work on a more realistic collision events with pileup interactions for hadrons within ``jets`` where these corrections would play a most important role; however, results shown here are promising and motivate further exploration.

%(for the calibration  DRN vs Chi2)
%The results of the 

%\subsection{EH Hadrons}
%The presented results are for the training target ratioflip

%\subsection{H hadrons}
\include{./plots_tex/target_ratioflip_H_plots}
\include{./plots_tex/target_logratioflip_H_plots}
\include{./plots_tex/target_ratio_H_plots}
\include{./plots_tex/target_trueE_H_plots}

\include{./plots_tex/target_ratioflip_EH_plots}
\include{./plots_tex/target_logratioflip_EH_plots}
\include{./plots_tex/target_ratio_EH_plots}
\include{./plots_tex/target_trueE_EH_plots}
